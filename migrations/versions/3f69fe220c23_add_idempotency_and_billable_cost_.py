"""Add idempotency and billable cost fields to usage_logs

Revision ID: 3f69fe220c23
Revises: d4187500b13c
Create Date: 2026-02-11 23:29:11.781710

"""

from typing import Sequence, Union
from uuid import uuid4
from decimal import Decimal

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "3f69fe220c23"
down_revision: Union[str, Sequence[str], None] = "d4187500b13c"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema.

    Add new fields for idempotency and billable cost tracking:
    - request_id: Globally unique ID for idempotency (NOT NULL, UNIQUE)
    - endpoint: API endpoint path (NOT NULL)
    - method: HTTP method (NOT NULL)
    - client_ip: Optional client IP address
    - client_user_agent: Optional user agent
    - usage_estimate: JSON for usage estimation data
    - credits_reserved: Billable cost in credits (NOT NULL)

    Remove old field:
    - cost: Old JSON cost field (replaced by credits_reserved)
    """
    # Step 1: Add columns as nullable first to handle existing data
    op.add_column(
        "usage_logs",
        sa.Column(
            "request_id",
            sa.String(),
            nullable=True,
            comment="Globally unique request ID for idempotency",
        ),
    )
    op.add_column(
        "usage_logs",
        sa.Column(
            "endpoint",
            sa.String(),
            nullable=True,
            comment="The API endpoint path being called",
        ),
    )
    op.add_column(
        "usage_logs",
        sa.Column(
            "method",
            sa.String(),
            nullable=True,
            comment="HTTP method (GET, POST, etc.)",
        ),
    )
    op.add_column(
        "usage_logs",
        sa.Column(
            "client_ip",
            sa.String(),
            nullable=True,
            comment="Optional client IP address",
        ),
    )
    op.add_column(
        "usage_logs",
        sa.Column(
            "client_user_agent",
            sa.String(),
            nullable=True,
            comment="Optional client user agent string",
        ),
    )
    op.add_column(
        "usage_logs",
        sa.Column(
            "usage_estimate",
            sa.JSON(),
            nullable=True,
            comment="Usage estimation data (input_chars, max_output_tokens, model)",
        ),
    )
    op.add_column(
        "usage_logs",
        sa.Column(
            "credits_reserved",
            sa.Numeric(precision=12, scale=4),
            nullable=True,
            comment="The billable cost in credits",
        ),
    )

    # Step 2: Backfill existing rows with default values
    # Generate unique request_ids for existing rows
    conn = op.get_bind()
    usage_logs = sa.table(
        "usage_logs",
        sa.column("id"),
        sa.column("request_id"),
        sa.column("endpoint"),
        sa.column("method"),
        sa.column("credits_reserved"),
    )

    # Get existing rows without request_id
    result = conn.execute(
        sa.select(usage_logs.c.id).where(usage_logs.c.request_id.is_(None))
    )
    for row in result:
        conn.execute(
            usage_logs.update()
            .where(usage_logs.c.id == row.id)
            .values(
                request_id=str(uuid4()),
                endpoint="/legacy/unknown",
                method="UNKNOWN",
                credits_reserved=Decimal("0.0000"),
            )
        )

    # Step 3: Add NOT NULL constraints
    op.alter_column("usage_logs", "request_id", nullable=False)
    op.alter_column("usage_logs", "endpoint", nullable=False)
    op.alter_column("usage_logs", "method", nullable=False)
    op.alter_column("usage_logs", "credits_reserved", nullable=False)

    # Step 4: Create indexes
    op.create_index("ix_usage_logs_endpoint", "usage_logs", ["endpoint"], unique=False)
    op.create_index(
        op.f("ix_usage_logs_request_id"), "usage_logs", ["request_id"], unique=True
    )

    # Step 5: Drop old cost column
    op.drop_column("usage_logs", "cost")


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "usage_logs",
        sa.Column(
            "cost",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
            comment="Usage cost/credits consumed (structure TBD by quota system)",
        ),
    )
    op.drop_index(op.f("ix_usage_logs_request_id"), table_name="usage_logs")
    op.drop_index("ix_usage_logs_endpoint", table_name="usage_logs")
    op.drop_column("usage_logs", "credits_reserved")
    op.drop_column("usage_logs", "usage_estimate")
    op.drop_column("usage_logs", "client_user_agent")
    op.drop_column("usage_logs", "client_ip")
    op.drop_column("usage_logs", "method")
    op.drop_column("usage_logs", "endpoint")
    op.drop_column("usage_logs", "request_id")
    # ### end Alembic commands ###
